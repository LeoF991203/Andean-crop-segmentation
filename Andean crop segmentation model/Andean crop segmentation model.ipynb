{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6b81172",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47d8878c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x254a00463f0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio import plot\n",
    "import numpy as np\n",
    "from rasterio.plot import show\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e836bd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr  4 19:01:55 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 546.80                 Driver Version: 546.80       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080 ...  WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   59C    P8              12W / 120W |    407MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     35672      C   ...tesis_remotesensing_egpu\\python.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6841e8",
   "metadata": {},
   "source": [
    "# Preprocessing of images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3559be4",
   "metadata": {},
   "source": [
    "## Retrieving the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb84ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Retrieve the splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ab314c",
   "metadata": {},
   "source": [
    "## Splitting the dataset in training, val and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a35e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split the data into train, val, and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877d17a3",
   "metadata": {},
   "source": [
    "# Segmentation model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a65768",
   "metadata": {},
   "source": [
    "## Base model (Unet) and steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addf524c",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acc2d32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (enc1): Sequential(\n",
      "    (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (enc2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (enc3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (enc4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (bottleneck): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (dec4): Sequential(\n",
      "    (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (dec4_conv): Sequential(\n",
      "    (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (dec3): Sequential(\n",
      "    (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (dec3_conv): Sequential(\n",
      "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (dec2): Sequential(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (dec2_conv): Sequential(\n",
      "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (dec1): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (dec1_conv): Sequential(\n",
      "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (final): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=4, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        def conv_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        \n",
    "        def up_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        \n",
    "        self.enc1 = conv_block(in_channels, 64)\n",
    "        self.enc2 = conv_block(64, 128)\n",
    "        self.enc3 = conv_block(128, 256)\n",
    "        self.enc4 = conv_block(256, 512)\n",
    "        \n",
    "        self.bottleneck = conv_block(512, 1024)\n",
    "        \n",
    "        self.dec4 = up_block(1024, 512)\n",
    "        self.dec4_conv = conv_block(1024, 512)\n",
    "        self.dec3 = up_block(512, 256)\n",
    "        self.dec3_conv = conv_block(512, 256)\n",
    "        self.dec2 = up_block(256, 128)\n",
    "        self.dec2_conv = conv_block(256, 128)\n",
    "        self.dec1 = up_block(128, 64)\n",
    "        self.dec1_conv = conv_block(128, 64)\n",
    "        \n",
    "        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(nn.MaxPool2d(2)(enc1))\n",
    "        enc3 = self.enc3(nn.MaxPool2d(2)(enc2))\n",
    "        enc4 = self.enc4(nn.MaxPool2d(2)(enc3))\n",
    "        \n",
    "        bottleneck = self.bottleneck(nn.MaxPool2d(2)(enc4))\n",
    "        \n",
    "        dec4 = self.dec4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.dec4_conv(dec4)\n",
    "        \n",
    "        dec3 = self.dec3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.dec3_conv(dec3)\n",
    "        \n",
    "        dec2 = self.dec2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.dec2_conv(dec2)\n",
    "        \n",
    "        dec1 = self.dec1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.dec1_conv(dec1)\n",
    "        \n",
    "        return self.final(dec1)\n",
    "\n",
    "# Instantiate the model\n",
    "unet_model = UNet(in_channels=4, out_channels=1)\n",
    "print(unet_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb59a94",
   "metadata": {},
   "source": [
    "### Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791c90b2",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5597b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis_remotesensing_egpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
